Spark Command: /usr/lib/jvm/java-17-openjdk-amd64/bin/java -cp /root/star/learn_project/spark/spark/conf/:/root/star/learn_project/spark/spark/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://localhost:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
24/06/06 17:59:16 INFO Worker: Started daemon with process name: 14267@iZ0jlhg70whffl7h9r366sZ
24/06/06 17:59:16 INFO SignalUtils: Registering signal handler for TERM
24/06/06 17:59:16 INFO SignalUtils: Registering signal handler for HUP
24/06/06 17:59:16 INFO SignalUtils: Registering signal handler for INT
24/06/06 17:59:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/06/06 17:59:16 INFO SecurityManager: Changing view acls to: root
24/06/06 17:59:16 INFO SecurityManager: Changing modify acls to: root
24/06/06 17:59:16 INFO SecurityManager: Changing view acls groups to: 
24/06/06 17:59:16 INFO SecurityManager: Changing modify acls groups to: 
24/06/06 17:59:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
24/06/06 17:59:16 INFO Utils: Successfully started service 'sparkWorker' on port 46117.
24/06/06 17:59:16 INFO Worker: Worker decommissioning not enabled.
24/06/06 17:59:16 INFO Worker: Starting Spark worker 172.19.162.152:46117 with 4 cores, 14.0 GiB RAM
24/06/06 17:59:17 INFO Worker: Running Spark version 3.5.1
24/06/06 17:59:17 INFO Worker: Spark home: /root/star/learn_project/spark/spark
24/06/06 17:59:17 INFO ResourceUtils: ==============================================================
24/06/06 17:59:17 INFO ResourceUtils: No custom resources configured for spark.worker.
24/06/06 17:59:17 INFO ResourceUtils: ==============================================================
24/06/06 17:59:17 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
24/06/06 17:59:17 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/06/06 17:59:17 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://iZ0jlhg70whffl7h9r366sZ:8081
24/06/06 17:59:17 INFO Worker: Connecting to master localhost:7077...
24/06/06 17:59:17 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:7077 after 28 ms (0 ms spent in bootstraps)
24/06/06 17:59:17 INFO Worker: Successfully registered with master spark://localhost:7077
24/06/06 18:00:23 INFO Worker: Asked to launch executor app-20240606180023-0000/0 for Spark shell
24/06/06 18:00:23 INFO SecurityManager: Changing view acls to: root
24/06/06 18:00:23 INFO SecurityManager: Changing modify acls to: root
24/06/06 18:00:23 INFO SecurityManager: Changing view acls groups to: 
24/06/06 18:00:23 INFO SecurityManager: Changing modify acls groups to: 
24/06/06 18:00:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
24/06/06 18:00:23 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk-amd64/bin/java" "-cp" "/root/star/learn_project/spark/spark/conf/:/root/star/learn_project/spark/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40275" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@iZ0jlhg70whffl7h9r366sZ:40275" "--executor-id" "0" "--hostname" "172.19.162.152" "--cores" "4" "--app-id" "app-20240606180023-0000" "--worker-url" "spark://Worker@172.19.162.152:46117" "--resourceProfileId" "0"
24/06/06 18:14:44 INFO Worker: Asked to kill executor app-20240606180023-0000/0
24/06/06 18:14:44 INFO ExecutorRunner: Runner thread for executor app-20240606180023-0000/0 interrupted
24/06/06 18:14:44 INFO ExecutorRunner: Killing process!
24/06/06 18:14:44 INFO Worker: Executor app-20240606180023-0000/0 finished with state KILLED exitStatus 0
24/06/06 18:14:44 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/06/06 18:14:44 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240606180023-0000, execId=0)
24/06/06 18:14:44 INFO ExternalShuffleBlockResolver: Application app-20240606180023-0000 removed, cleanupLocalDirs = true
24/06/06 18:14:44 INFO Worker: Cleaning up local directories for application app-20240606180023-0000
24/06/06 20:02:51 INFO Worker: Asked to launch executor app-20240606200251-0001/0 for Spark shell
24/06/06 20:02:51 INFO SecurityManager: Changing view acls to: root
24/06/06 20:02:51 INFO SecurityManager: Changing modify acls to: root
24/06/06 20:02:51 INFO SecurityManager: Changing view acls groups to: 
24/06/06 20:02:51 INFO SecurityManager: Changing modify acls groups to: 
24/06/06 20:02:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
24/06/06 20:02:51 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-17-openjdk-amd64/bin/java" "-cp" "/root/star/learn_project/spark/spark/conf/:/root/star/learn_project/spark/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45515" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@iZ0jlhg70whffl7h9r366sZ:45515" "--executor-id" "0" "--hostname" "172.19.162.152" "--cores" "4" "--app-id" "app-20240606200251-0001" "--worker-url" "spark://Worker@172.19.162.152:46117" "--resourceProfileId" "0"
24/06/06 20:03:36 INFO Worker: Asked to kill executor app-20240606200251-0001/0
24/06/06 20:03:36 INFO ExecutorRunner: Runner thread for executor app-20240606200251-0001/0 interrupted
24/06/06 20:03:36 INFO ExecutorRunner: Killing process!
24/06/06 20:03:37 INFO Worker: Executor app-20240606200251-0001/0 finished with state KILLED exitStatus 143
24/06/06 20:03:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
24/06/06 20:03:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20240606200251-0001, execId=0)
24/06/06 20:03:37 INFO ExternalShuffleBlockResolver: Application app-20240606200251-0001 removed, cleanupLocalDirs = true
24/06/06 20:03:37 INFO Worker: Cleaning up local directories for application app-20240606200251-0001
24/06/07 23:15:27 INFO Worker: localhost:7077 Disassociated !
24/06/07 23:15:27 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
24/06/07 23:15:27 INFO Worker: localhost:7077 Disassociated !
24/06/07 23:15:27 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
24/06/07 23:15:27 INFO Worker: Connecting to master localhost:7077...
24/06/07 23:15:27 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
24/06/07 23:15:27 INFO TransportClientFactory: Found inactive connection to localhost/127.0.0.1:7077, creating a new one.
24/06/07 23:15:27 WARN Worker: Failed to connect to master localhost:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.IOException: Failed to connect to localhost/127.0.0.1:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:7077
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/06/07 23:15:34 INFO Worker: Retrying connection to master (attempt # 1)
24/06/07 23:15:34 INFO Worker: Connecting to master localhost:7077...
24/06/07 23:15:34 INFO TransportClientFactory: Found inactive connection to localhost/127.0.0.1:7077, creating a new one.
24/06/07 23:15:34 WARN Worker: Failed to connect to master localhost:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.deploy.worker.Worker$$anon$2.run(Worker.scala:370)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.io.IOException: Failed to connect to localhost/127.0.0.1:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:7077
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:840)
24/06/07 23:15:41 ERROR Worker: RECEIVED SIGNAL TERM
24/06/07 23:15:41 INFO ShutdownHookManager: Shutdown hook called
24/06/07 23:15:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-d6d3a9b2-462e-444d-9db1-f7047b24a751
